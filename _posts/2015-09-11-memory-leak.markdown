---
layout: post
title:  "Как я провёл две недели в поисках утечки памяти"
date:   2015-09-11 17:20:38
categories: jekyll update
---

Неприятная данность: у нашего Rails-приложения, работающего на платформе [Heroku](http://heroku.com),
«течёт» память. Это заметно на графике:

![Потребление памяти web-процессами](/assets/heroku_metrics_memleak.png)

После каждого деплоя или перезапуска потребление памяти резко возрастает (см. в районе 3&nbsp;AM), и это нормально, ведь
Ruby язык динамический. Срабатывают какие-то `require`, что-то догружается. После этого потребление памяти должно болтаться
вокруг горизонтальной линии. Обработали запрос, насоздавали объектов — вверх. Сработал сборщик мусора — вниз.
По идее, в таком динамическом балансе приложение может находится сколь угодно долго.
Но если есть утечка, на графике возникает стабильный тренд вверх.

Далее я расскажу, как искал утечку.

# Локальное повторение проблемы

Production-сервер — не место для экспериментов. Поэтому первое, что я сделал —
скачал дамп production-базы и запустил приложение в production-окружении на моём
тестовом Linux-сервере, стоящем в кладовке (у вас же, конечно, есть такой?). Наше
приложение — SaaS-продукт, в специальной middleware по домену определяется сайт
клиента, поэтому пришлось немного подправить код, чтобы можно было делать запросы
вида `curl http://localhost:3000/…`. Здесь очень удобны переменные окружения.

{% highlight ruby %}
if ENV['QUERY_SITE_ID']
  def find_site(request)
    Site.find_by_id_cached(request.query_parameters[:site_id])
  end
else
  # Private: Look up for site.
  #
  # Tries to find by domain, subdomain, or use canned site in test environment.
  #
  # Returns Site instance or falsey value.
  def find_site(request)
    host = request.host

    # …
  end
end
{% endhighlight %}

Как видно, если установлена переменная окружения `QUERY_SITE_ID`, то ID сайта
будет определяться из параметра запроса `site_id`:

`curl http://localhost:3000/?site_id=123`

Также в `config/environments/production.rb` понадобится поставить
`config.force_ssl = false`,
установить переменную `DEVISE_SECRET_KEY`, и возможно что-то ещё. Нужно добиваться,
чтобы приведённая выше команда curl сработала.

Итак, сервер запустился, что дальше? Теперь нужно дать на него нагрузку.
Для этого есть прекрасная утилита [siege](https://www.joedog.org/siege-manual/), позволяющая мучать сервера в разных
режимах и собирать статистику. Я решил не долбиться по одному URL, а собрать
реальные адреса, по которым заходят клиенты. Это сделать несложно: запускаете на
какое-то время `heroku logs -t | tee log/production.log`, потом из лога остаётся
выкусить адреса. Я написал для этого небольшую утилиту, которая парсила лог,
собирала адреса, site_id, печатаемые middleware, и генерировала файл urls.txt
в формате:

{% highlight text %}
http://localhost:3000/foo
http://localhost:3000/bar
http://localhost:3000/baz
{% endhighlight %}

Такой файл также можно сделать вручную, или воспользоваться коктейлем из awk, grep, sed.

Запускаем siege:

`siege -v -c 15  --log=/tmp/siege.log -f urls.txt`

Здесь siege создаст 15 параллельных клиентов. У меня
приложение работало с веб-сервером [puma](http://puma.io) в одиночном режиме с
максимум 16 потоками.

Если всё было сделано правильно, память должна начать «течь». Это можно увидеть
с помощью утилит `top`, `ps` — соответствующий показатель называется RSS (Resident Set Size).
Чтобы не мучаться с их запуском, я добавил в приложение вот такой код:

{% highlight ruby %}
if ENV['MEMORY_REPORTING']
  Thread.new do
    while true
      pid = Process.pid
      rss = `ps -eo pid,rss | grep #{pid} | awk '{print $2}'`.to_i
      Rails.logger.info "MEMORY[#{pid}]: rss: #{rss}, live objects #{GC.stat[:heap_live_slots]}"

      sleep 5
    end
  end
end
{% endhighlight %}

В логе стали появляться аккуратные записи с растущим RSS… Про `GC.stat[:heap_live_slots]`
см. дальше.

# Поиск утечки в Ruby коде

Убедившись в реальности утечки, я приступил к её поиску.

Здесь нужно немного остановиться на том, как устроена память в MRI вообще. Объекты
хранятся в куче, которой управляет интерпретатор. Куча состоит из отдельных страниц размером
16 килобайт, на каждый объект выделяется 40 байт. При создании объекта идёт поиск свободной ячейки,
если таковых нет, создаётся новая страница. Конечно, не все объекты помещаются в 40 байт. Если памяти требуется
больше, дополнительная память выделяется отдельно (с помощью `malloc`).

Освобождение памяти происходит автоматически в процессе работы сборщика мусора (GC). Современные MRI
имеют довольно эффективный GC с несколькими поколениями и двумя фазами: малой и большой. Опираясь на
эвристический принцип «большинство объектов имеют небольшое время жизни», _малый цикл сборки мусора_ ищет и освобождает
ненужные объекты только среди недавно созданных. Это позволяет реже запускать _большой цикл_, который
подвергает классическому алгоритму Mark-and-Sweep **ВСЕ** объекты.

Нужно отметить, что для поиска утечек тонкости различных поколений совершенно не
важны. Существенно одно: будут ли освобождены все объекты, порождаемые в процессе
обработки запроса, или нет. Заметим, что в контексте веб-сервера все порождаемые
объекты можно разделить на три группы:

1. *Статика*. Это все загруженные гемы, особенно Rails и код приложения. В production-окружении
всё это грузится один раз и практически не изменяется.
2. *Медленная динамика*. Есть некоторое количество долгоживущих объектов, например, кеш
prepared SQL-запросов в ActiveRecord. Этот кеш, по умолчанию имеющий размер 1000 элементов
на каждое соединение с ДБ, будет потихоньку заполняться, и количество объектов будет расти,
пока не дойдёт до предела (2000 строк * количество соединений).
3. *Быстрая динамика*. Это все объекты, порождаемые в процессе обработки запроса и генерации ответа.
После того, как ответ готов, объекты могут быть освобождены.

Если в третьем случае какой-то объект не будет освобожден, будет утечка. Это легко
проиллюстрировать так:

{% highlight ruby %}
class MyController < ApplicationController
  FOO = []

  def index
    FOO << "haha"
  end
end
{% endhighlight %}

Константы не подлежат сборке мусора, и последовательные вызовы `MyController#index`
будут приводить к распуханию массива `FOO`. При этом куча будет расти из-за того,
что ячейки будут забиваться новыми и новыми строками `"haha"`.

Если утечек нет, размер кучи будет колебаться. Минимальный размер кучи соответствует
объектам из п.1 и п.2 (см. выше). Например, у нашего приложения это чуть больше 500000 объектов
(пустое приложение сразу после `rails new app` даёт где-то 300000). Максимальный размер кучи
зависит от того, насколько будет успевать срабатывать большой цикл сборки мусора. **Но:** после
большого цикла количество объектов будет всегда возвращаться к нижней границе, которая изменяться не будет.
Утечки будут приводить к тому, что нижняя граница поплывёт.

Удобнее всего исследовать эти вещи с помощью гема [gc_tracer](https://github.com/ko1/gc_tracer),
созданного Koichi Sasada, членом команды разработчиков Ruby и автором инкрементального сборщика мусора
в Ruby 2.1 и 2.2. Добавив

{% highlight ruby %}
require 'rack/gc_tracer'
config.middleware.use Rack::GCTracerMiddleware, view_page_path: '/gc_tracer', filename: 'log/gc.log'
{% endhighlight %}

в `config/application.rb`, мы получаем файл `log/gc.log`, который будет наполняться статистикой работы
сборщика мусора и результатами вызова `getrusage` (последнее полезно, потому что одно из полей содержит
интересующую нас цифру RSS).

В каждой строке этого лога около 50 значений и глаза разбегаются, однако мы можем использовать несложную магию UNIX.
Вот команда, которую я запускал параллельно с `puma` и `siege`:

`tail -f log/gc.log | cut -f 2,4,7,8,9,15,16,19,21,22,25,26,27,28,29,30,36`

Самое первое в строке — timestamp в миллисекундах. Второе — количество страниц. Третье — общий размер кучи в единицах объектов.
Одиннадцатое — количество «старых» объектов, т.е. тех, которые не обрабатываются в малом цикле сборки мусора. Самое последнее — RSS.

Но даже так цифр слишком много. Что ж, построим график! Конечно, можно лог
непосредственно загнать в эксель, но это не наш путь. Гораздо лучше воспользоваться
[gnuplot](http://www.gnuplot.info/), который умеет рисовать графики прямо из таких файлов.

К сожалению, gnuplot не поддерживает формат времени с миллисекундами, поэтому пришлось
написать маленький скрипт для преобразования времени:

{% highlight bash %}
#!/bin/sh

cat $1|awk '{if($1=="end_sweep"||FNR==1) {if(FNR>1) {$2=substr($2,1,length($2)-6)} else {$2=$2}; print $0}}' > $2
{% endhighlight %}

Помимо приведения временных отсчётов к секундам здесь отбрасывается лишняя информация. gc_tracer генерирует данные
на всех фазах работы сборки мусора, но нас будет интересовать только конец (end_sweep).

С помощью вот такого gnuplot-скрипта:
{% highlight gnuplot %}
set xdata time
set timefmt '%s'
set format x '%H:%M'
set y2tics on
set y2label 'Kilobytes'
set ylabel 'Objects'
plot 'gc.log.22' using 2:25 with lines title columnhead, '' using 2:36 with lines lc rgb 'blue' title columnhead axes x1y2
{% endhighlight  %}
получаем картинку:

![Количество «старых» объектов и RSS от времени](/assets/olds_vs_rss.png)

Красная кривая (левая шкала) — количество «старых» объектов. Оно ведёт себя так, будто никакой
утечки памяти нет. Синяя кривая (правая шкала) — RSS. А оно растёт…

Вывод простой: **в Ruby коде утечек нет**. Однако я не сразу догадался до этого
и сходил еще по ложному пути.

# Ложный путь. Возня с дампами кучи
